"""M√≥dulo de detec√ß√£o de Informa√ß√µes Pessoais Identific√°veis (PII).

Vers√£o: 9.1 - HACKATHON PARTICIPA-DF 2025
Abordagem: Ensemble h√≠brido com alta recall (estrat√©gia OR)
Confian√ßa: Sistema probabil√≠stico com calibra√ß√£o e log-odds

Pipeline:
1. Regras determin√≠sticas (regex + valida√ß√£o DV) ‚Üí 70% dos PIIs
2. NER especializado (BERTimbau NER) ‚Üí nomes e entidades
3. spaCy como backup ‚Üí cobertura adicional
4. Ensemble OR ‚Üí qualquer detector positivo = PII
5. C√°lculo probabil√≠stico de confian√ßa ‚Üí calibra√ß√£o + log-odds
"""

import re
from typing import List, Dict, Tuple, Optional, Set
from dataclasses import dataclass, field
from enum import Enum
from functools import lru_cache
import logging
from text_unidecode import unidecode

# M√≥dulo de confian√ßa probabil√≠stica
try:
    from .confidence import (
        PIIConfidenceCalculator,
        get_calculator,
        DocumentConfidence as DocConf,
        PESOS_LGPD as PESOS_LGPD_CONF
    )
    CONFIDENCE_MODULE_AVAILABLE = True
except ImportError:
    CONFIDENCE_MODULE_AVAILABLE = False
    PIIConfidenceCalculator = None

# Configura√ß√£o de logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class RiscoLevel(Enum):
    """N√≠veis de risco para classifica√ß√£o."""
    CRITICO = 5
    ALTO = 4
    MODERADO = 3
    BAIXO = 2
    SEGURO = 0


@dataclass
class PIIFinding:
    """Estrutura para achados de PII."""
    tipo: str
    valor: str
    confianca: float
    peso: int
    inicio: int = 0
    fim: int = 0
    contexto: str = ""
    
    def __hash__(self):
        return hash((self.tipo, self.valor.lower().strip()))
    
    def __eq__(self, other):
        if not isinstance(other, PIIFinding):
            return False
        return self.valor.lower().strip() == other.valor.lower().strip()


class ValidadorDocumentos:
    """Valida√ß√£o de documentos brasileiros com d√≠gito verificador."""
    
    @staticmethod
    def validar_cpf(cpf: str) -> bool:
        """Valida CPF com d√≠gito verificador.
        
        Retorna True se o CPF √© estruturalmente v√°lido.
        CPFs com todos d√≠gitos iguais s√£o inv√°lidos (exceto sequ√™ncias espec√≠ficas).
        """
        # Remove formata√ß√£o
        numeros = re.sub(r'[^\d]', '', cpf)
        
        if len(numeros) != 11:
            return False
        
        # CPFs com todos d√≠gitos iguais s√£o inv√°lidos
        if len(set(numeros)) == 1:
            return False
        
        # Calcula primeiro d√≠gito verificador
        soma = sum(int(numeros[i]) * (10 - i) for i in range(9))
        resto = soma % 11
        dv1 = 0 if resto < 2 else 11 - resto
        
        if int(numeros[9]) != dv1:
            return False
        
        # Calcula segundo d√≠gito verificador
        soma = sum(int(numeros[i]) * (11 - i) for i in range(10))
        resto = soma % 11
        dv2 = 0 if resto < 2 else 11 - resto
        
        return int(numeros[10]) == dv2
    
    @staticmethod
    def validar_cnpj(cnpj: str) -> bool:
        """Valida CNPJ com d√≠gito verificador."""
        numeros = re.sub(r'[^\d]', '', cnpj)
        
        if len(numeros) != 14:
            return False
        
        if len(set(numeros)) == 1:
            return False
        
        # Pesos para c√°lculo
        pesos1 = [5, 4, 3, 2, 9, 8, 7, 6, 5, 4, 3, 2]
        pesos2 = [6, 5, 4, 3, 2, 9, 8, 7, 6, 5, 4, 3, 2]
        
        # Primeiro d√≠gito
        soma = sum(int(numeros[i]) * pesos1[i] for i in range(12))
        resto = soma % 11
        dv1 = 0 if resto < 2 else 11 - resto
        
        if int(numeros[12]) != dv1:
            return False
        
        # Segundo d√≠gito
        soma = sum(int(numeros[i]) * pesos2[i] for i in range(13))
        resto = soma % 11
        dv2 = 0 if resto < 2 else 11 - resto
        
        return int(numeros[13]) == dv2
    
    @staticmethod
    def validar_pis(pis: str) -> bool:
        """Valida PIS/PASEP/NIT com d√≠gito verificador."""
        numeros = re.sub(r'[^\d]', '', pis)
        
        if len(numeros) != 11:
            return False
        
        pesos = [3, 2, 9, 8, 7, 6, 5, 4, 3, 2]
        soma = sum(int(numeros[i]) * pesos[i] for i in range(10))
        resto = soma % 11
        dv = 0 if resto < 2 else 11 - resto
        
        return int(numeros[10]) == dv
    
    @staticmethod
    def validar_titulo_eleitor(titulo: str) -> bool:
        """Valida t√≠tulo de eleitor."""
        numeros = re.sub(r'[^\d]', '', titulo)
        
        if len(numeros) != 12:
            return False
        
        # Sequ√™ncia do estado (posi√ß√µes 8-9)
        uf = int(numeros[8:10])
        if uf < 1 or uf > 28:
            return False
        
        return True
    
    @staticmethod
    def validar_cns(cns: str) -> bool:
        """Valida Cart√£o Nacional de Sa√∫de (CNS)."""
        numeros = re.sub(r'[^\d]', '', cns)
        
        if len(numeros) != 15:
            return False
        
        # CNS definitivo come√ßa com 1 ou 2
        # CNS provis√≥rio come√ßa com 7, 8 ou 9
        primeiro = int(numeros[0])
        if primeiro not in [1, 2, 7, 8, 9]:
            return False
        
        # Valida√ß√£o do d√≠gito verificador
        if primeiro in [1, 2]:
            # CNS definitivo
            soma = sum(int(numeros[i]) * (15 - i) for i in range(15))
            return soma % 11 == 0
        else:
            # CNS provis√≥rio
            soma = sum(int(numeros[i]) * (15 - i) for i in range(15))
            return soma % 11 == 0
        
        return True


class PIIDetector:
    """Detector h√≠brido de PII com ensemble de alta recall.
    
    Estrat√©gia: Ensemble OR - qualquer detector positivo classifica como PII.
    Isso maximiza recall (n√£o deixar escapar nenhum PII) √†s custas de alguns
    falsos positivos, que √© a estrat√©gia correta para LAI/LGPD.
    
    Confian√ßa: Sistema probabil√≠stico com:
    - Calibra√ß√£o isot√¥nica de scores de modelos
    - Combina√ß√£o via Log-Odds (Naive Bayes)
    - Valida√ß√£o de DV como fonte adicional
    """

    def __init__(self, usar_gpu: bool = True, use_probabilistic_confidence: bool = True) -> None:
        """Inicializa o detector com todos os modelos NLP.
        
        Args:
            usar_gpu: Se deve usar GPU para modelos (default: True)
            use_probabilistic_confidence: Se deve usar sistema de confian√ßa 
                probabil√≠stica (default: True)
        """
        logger.info("üèÜ [v9.1] VERS√ÉO HACKATHON - ENSEMBLE DE ALTA RECALL + CONFIAN√áA PROBABIL√çSTICA")
        
        self.validador = ValidadorDocumentos()
        self._inicializar_modelos(usar_gpu)
        self._inicializar_vocabularios()
        self._compilar_patterns()
        
        # Sistema de confian√ßa probabil√≠stica
        self.use_probabilistic_confidence = use_probabilistic_confidence and CONFIDENCE_MODULE_AVAILABLE
        if self.use_probabilistic_confidence:
            self.confidence_calculator = get_calculator()
            logger.info("‚úÖ Sistema de confian√ßa probabil√≠stica ativado")
        else:
            self.confidence_calculator = None
            if use_probabilistic_confidence and not CONFIDENCE_MODULE_AVAILABLE:
                logger.warning("‚ö†Ô∏è M√≥dulo de confian√ßa n√£o dispon√≠vel, usando fallback")
    
    def _inicializar_modelos(self, usar_gpu: bool) -> None:
        """Carrega modelos NLP com fallback."""
        import spacy
        from transformers import pipeline, AutoModelForTokenClassification, AutoTokenizer
        
        # spaCy - modelo grande para portugu√™s
        try:
            self.nlp_spacy = spacy.load("pt_core_news_lg")
            logger.info("‚úÖ spaCy pt_core_news_lg carregado")
        except OSError:
            try:
                self.nlp_spacy = spacy.load("pt_core_news_md")
                logger.warning("‚ö†Ô∏è Usando pt_core_news_md (fallback)")
            except OSError:
                self.nlp_spacy = None
                logger.error("‚ùå Nenhum modelo spaCy dispon√≠vel")
        
        # BERT NER - Modelo multil√≠ngue treinado para NER
        # Suporta: PER (pessoas), ORG (organiza√ß√µes), LOC (locais), DATE (datas)
        # Funciona muito bem para portugu√™s brasileiro
        
        # Detecta automaticamente se h√° GPU dispon√≠vel
        import torch
        if usar_gpu and torch.cuda.is_available():
            device = 0  # GPU
            logger.info("üöÄ GPU detectada, usando CUDA para BERT")
        else:
            device = -1  # CPU
        
        try:
            # Modelo multil√≠ngue NER - treinado em 10+ idiomas incluindo portugu√™s
            # Labels: O, B-PER, I-PER, B-ORG, I-ORG, B-LOC, I-LOC, B-DATE, I-DATE
            self.nlp_bert = pipeline(
                "ner",
                model="Davlan/bert-base-multilingual-cased-ner-hrl",
                aggregation_strategy="simple",
                device=device
            )
            logger.info("‚úÖ BERT NER multil√≠ngue carregado (PER, ORG, LOC, DATE)")
        except Exception as e:
            self.nlp_bert = None
            logger.warning(f"‚ö†Ô∏è BERT NER n√£o dispon√≠vel: {e}. Usando apenas spaCy para NER.")
    
    def _inicializar_vocabularios(self) -> None:
        """Inicializa todos os vocabul√°rios e listas de contexto."""
        
        # Palavras que NUNCA s√£o PII
        self.blocklist_total: Set[str] = {
            # Sauda√ß√µes e formalidades
            "AGRADECO", "ATENCIOSAMENTE", "CORDIALMENTE", "RESPEITOSAMENTE",
            "BOM DIA", "BOA TARDE", "BOA NOITE", "PREZADOS", "PREZADO", "PREZADA",
            
            # A√ß√µes administrativas
            "SOLICITO", "INFORMO", "ENCAMINHO", "DESPACHO", "PROCESSO", "AUTOS",
            "REQUERIMENTO", "PROTOCOLO", "MANIFESTACAO", "DEMANDA",
            
            # Tratamentos
            "DRA", "DR", "SR", "SRA", "PROF", "PROFESSOR", "PROFESSORA",
            "DOUTOR", "DOUTORA", "EXCELENTISSIMO", "EXCELENTISSIMA",
            
            # Estrutura organizacional
            "SECRETARIA", "DEPARTAMENTO", "DIRETORIA", "GERENCIA", "COORDENACAO",
            "SUPERINTENDENCIA", "SUBSECRETARIA", "ASSESSORIA", "GABINETE",
            
            # Termos comuns em LAI
            "CIDADAO", "CIDADA", "REQUERENTE", "SOLICITANTE", "INTERESSADO",
            "DENUNCIANTE", "RECLAMANTE", "MANIFESTANTE",
            
            # Falsos positivos de NER (palavras que parecem nomes mas n√£o s√£o)
            "MEU CPF", "MINHA CNH", "MEU RG", "MEU TELEFONE", "MEU EMAIL",
            "MEU ENDERECO", "MINHA IDENTIDADE", "MEU NOME", "MEU PIS",
            
            # Outros
            "LIGACOES", "TELEFONICAS", "MUDAS", "ILUMINACAO", "PUBLICA",
            "OUVIDORIA", "RECLAMACAO", "DENUNCIA", "ELOGIO", "SUGESTAO",
            "JANEIRO", "FEVEREIRO", "MARCO", "ABRIL", "MAIO", "JUNHO",
            "JULHO", "AGOSTO", "SETEMBRO", "OUTUBRO", "NOVEMBRO", "DEZEMBRO"
        }
        
        # Termos institucionais/p√∫blicos do GDF - EXPANDIDO
        self.termos_seguros: Set[str] = {
            # √ìrg√£os do GDF
            "GDF", "PMDF", "PCDF", "CBMDF", "SEEDF", "SESDF", "SSP", "DETRAN",
            "BRB", "NOVACAP", "CGDF", "CLDF", "TCDF", "DODF", "SEI", "TERRACAP",
            "CAESB", "NEOENERGIA", "CEB", "METR√î-DF", "METRO DF", "DFTRANS",
            "AGEFIS", "ADASA", "CODHAB", "EMATER", "FAPDF", "INESP",
            
            # Regi√µes Administrativas
            "BRASILIA", "PLANO PILOTO", "GAMA", "TAGUATINGA", "BRAZLANDIA",
            "SOBRADINHO", "PLANALTINA", "PARANOA", "NUCLEO BANDEIRANTE",
            "CEILANDIA", "GUARA", "CRUZEIRO", "SAMAMBAIA", "SANTA MARIA",
            "SAO SEBASTIAO", "RECANTO DAS EMAS", "LAGO SUL", "LAGO NORTE",
            "CANDANGOLANDIA", "RIACHO FUNDO", "SUDOESTE", "OCTOGONAL",
            "VARJAO", "PARK WAY", "SCIA", "ESTRUTURAL", "JARDIM BOTANICO",
            "ITAPOA", "SIA", "VICENTE PIRES", "FERCAL", "SOL NASCENTE",
            "POR DO SOL", "ARNIQUEIRA", "AGUAS CLARAS",
            
            # Endere√ßos administrativos de Bras√≠lia
            "ASA SUL", "ASA NORTE", "EIXO MONUMENTAL", "ESPLANADA DOS MINISTERIOS",
            "W3", "L2", "SQS", "SQN", "SRES", "SHIS", "SHIN", "SHLN", "SGAS", "SGAN",
            "SRTVS", "SRTVN", "SCN", "SCS", "SBS", "SBN", "SDN", "SDS",
            
            # Tribunais e √≥rg√£os federais em Bras√≠lia
            "STF", "STJ", "TST", "TSE", "STM", "TJDFT", "TRF1", "TRT10",
            "MPF", "MPDFT", "DPU", "AGU", "CGU", "TCU", "SENADO", "CAMARA"
        }
        
        # Indicadores de servidor p√∫blico
        self.indicadores_servidor: Set[str] = {
            "SERVIDOR", "SERVIDORA", "FUNCIONARIO", "FUNCIONARIA",
            "ANALISTA", "TECNICO", "T√âCNICO", "AUDITOR", "FISCAL",
            "PERITO", "DELEGADO", "DELEGADA", "ADMINISTRADOR", "ADMINISTRADORA",
            "COORDENADOR", "COORDENADORA", "DIRETOR", "DIRETORA",
            "SECRETARIO", "SECRET√ÅRIA", "SECRETARIA",
            "AGENTE", "MEDICO", "M√âDICO", "MEDICA", "M√âDICA",
            "ASSESSOR", "ASSESSORA", "CHEFE", "GERENTE",
            "SUPERINTENDENTE", "SUBSECRETARIO", "SUBSECRET√ÅRIA"
        }
        
        # Cargos que conferem imunidade em contexto funcional
        self.cargos_autoridade: Set[str] = {
            "DRA", "DR", "SR", "SRA", "PROF", "DOUTOR", "DOUTORA",
            "EXMO", "EXMA", "ILMO", "ILMA", "MM", "MERITISSIMO"
        }
        
        # Gatilhos que ANULAM imunidade (indicam contato pessoal)
        self.gatilhos_contato: Set[str] = {
            "FALAR COM", "TRATAR COM", "LIGAR PARA", "CONTATO COM",
            "TELEFONE DO", "TELEFONE DA", "CELULAR DO", "CELULAR DA",
            "WHATSAPP DO", "WHATSAPP DA", "EMAIL DO", "EMAIL DA",
            "FALAR COM O", "FALAR COM A", "CONTATO DO", "CONTATO DA",
            "PROCURAR", "CHAMAR", "AVISAR", "COMUNICAR COM",
            "ENDERECO DO", "ENDERECO DA", "RESIDENCIA DO", "RESIDENCIA DA",
            "CASA DO", "CASA DA", "MORA NA", "MORA NO", "RESIDE NA", "RESIDE NO"
        }
        
        # Contextos que indicam informa√ß√£o pessoal
        self.contextos_pii: Set[str] = {
            "MEU CPF", "MINHA IDENTIDADE", "MEU RG", "MINHA CNH",
            "MEU TELEFONE", "MEU CELULAR", "MEU EMAIL", "MEU E-MAIL",
            "MORO NA", "MORO NO", "RESIDO NA", "RESIDO NO",
            "MEU ENDERECO", "MINHA RESIDENCIA", "MINHA CASA",
            "MEU NOME COMPLETO", "ME CHAMO", "MEU NOME E",
            "MINHA CONTA", "MINHA AGENCIA", "MEU BANCO",
            "MEU PASSAPORTE", "MEU TITULO", "MEU PIS", "MEU NIT"
        }
        
        # Pesos por tipo de PII (baseado em categorias LGPD)
        self.pesos_pii: Dict[str, int] = {
            # Cr√≠tico (5) - Identifica√ß√£o direta
            "CPF": 5, "RG": 5, "CNH": 5, "PASSAPORTE": 5,
            "TITULO_ELEITOR": 5, "PIS": 5, "CNS": 5, "CNPJ_PESSOAL": 5,
            "CERTIDAO": 5, "CTPS": 5, "REGISTRO_PROFISSIONAL": 5,
            
            # Alto (4) - Contato direto
            "EMAIL_PESSOAL": 4, "TELEFONE": 4,
            "ENDERECO_RESIDENCIAL": 4, "NOME": 4,
            "CONTA_BANCARIA": 4, "PIX": 4, "CARTAO_CREDITO": 4,
            
            # Moderado (3) - Identifica√ß√£o indireta
            "PLACA_VEICULO": 3, "CEP": 3,
            "DATA_NASCIMENTO": 3, "PROCESSO_CNJ": 3,
        }
        
        # Confian√ßa BASE por tipo de PII (baseado no m√©todo de detec√ß√£o)
        # F√≥rmula final: confianca = min(1.0, base * fator_contexto)
        self.confianca_base: Dict[str, float] = {
            # Regex + Valida√ß√£o DV (alta confian√ßa)
            "CPF": 0.98,              # DV M√≥dulo 11
            "PIS": 0.98,              # DV M√≥dulo 11
            "CNS": 0.98,              # DV espec√≠fico
            "CNH": 0.98,              # DV M√≥dulo 11
            "TITULO_ELEITOR": 0.98,   # DV espec√≠fico
            "CTPS": 0.98,             # DV M√≥dulo 11
            "CARTAO_CREDITO": 0.95,   # Luhn (pode ser gerado)
            "CNPJ_PESSOAL": 0.90,     # DV + heur√≠stica MEI
            
            # Regex estrutural (sem DV)
            "EMAIL_PESSOAL": 0.95,    # Dom√≠nio pessoal confirmado
            "PROCESSO_CNJ": 0.90,     # Formato muito espec√≠fico
            "TELEFONE": 0.88,         # Pode ser comercial
            "PLACA_VEICULO": 0.88,    # Formato bem definido
            "PIX": 0.88,              # Chave identific√°vel
            "RG": 0.85,               # Formato varia por estado
            "PASSAPORTE": 0.85,       # Formato menos padronizado
            "ENDERECO_RESIDENCIAL": 0.85,
            "CONTA_BANCARIA": 0.85,
            "CERTIDAO": 0.85,
            "REGISTRO_PROFISSIONAL": 0.85,
            
            # Regex com depend√™ncia de contexto
            "CEP": 0.75,              # S√≥ com contexto pessoal
            "DATA_NASCIMENTO": 0.70,  # Muitas datas n√£o s√£o nascimento
            
            # NER
            "NOME_BERT": 0.00,        # Usa score do modelo (placeholder)
            "NOME_SPACY": 0.70,       # Modelo menor
            "NOME_GATILHO": 0.85,     # Padr√£o lingu√≠stico forte
            "NOME_CONTRA": 0.80,      # Padr√£o lingu√≠stico fraco
        }
    
    def _compilar_patterns(self) -> None:
        """Compila todos os patterns regex para performance."""
        
        self.patterns_compilados: Dict[str, re.Pattern] = {
            # === DOCUMENTOS DE IDENTIFICA√á√ÉO ===
            
            # CPF: 000.000.000-00 ou 00000000000
            'CPF': re.compile(
                r'\b(\d{3}[\.\s]?\d{3}[\.\s]?\d{3}[\-\.\s]?\d{2})\b',
                re.IGNORECASE
            ),
            
            # CNPJ: 00.000.000/0000-00 ou 00000000000000
            'CNPJ': re.compile(
                r'\b(\d{2}[\.\s]?\d{3}[\.\s]?\d{3}[/\.\s]?\d{4}[\-\.\s]?\d{2})\b',
                re.IGNORECASE
            ),
            
            # RG: diversos formatos estaduais
            'RG': re.compile(
                r'(?i)(?:RG|R\.G\.|IDENTIDADE|CARTEIRA DE IDENTIDADE)[:\s]*'
                r'[\(\[]?[A-Z]{0,2}[\)\]]?[\s\-]*'
                r'(\d{1,2}[\.\s]?\d{3}[\.\s]?\d{3}[\-\.\s]?[\dXx])',
                re.IGNORECASE
            ),
            
            # CNH: 00000000000 (11 d√≠gitos)
            'CNH': re.compile(
                r'(?i)(?:CNH|CARTEIRA DE MOTORISTA|HABILITACAO)[:\s]*'
                r'(\d{11})',
                re.IGNORECASE
            ),
            
            # PIS/PASEP/NIT: 000.00000.00-0
            'PIS': re.compile(
                r'\b(\d{3}[\.\s]?\d{5}[\.\s]?\d{2}[\-\.\s]?\d{1})\b',
                re.IGNORECASE
            ),
            
            # T√≠tulo de Eleitor: 0000 0000 0000 (12 d√≠gitos)
            'TITULO_ELEITOR': re.compile(
                r'(?i)(?:TITULO DE ELEITOR|TITULO ELEITORAL)[:\s]*'
                r'(\d{4}[\.\s]?\d{4}[\.\s]?\d{4})',
                re.IGNORECASE
            ),
            
            # CNS (Cart√£o SUS): 15 d√≠gitos come√ßando com 1, 2, 7, 8 ou 9
            'CNS': re.compile(
                r'\b([1-2789]\d{14})\b',
                re.IGNORECASE
            ),
            
            # Passaporte Brasileiro: AA000000 ou BR000000
            'PASSAPORTE': re.compile(
                r'(?i)(?:PASSAPORTE|PASSPORT)[:\s]*'
                r'(?:BR)?[\s]?([A-Z]{2}\d{6})',
                re.IGNORECASE
            ),
            
            # CTPS: 0000000/00000-UF
            'CTPS': re.compile(
                r'(?i)(?:CTPS|CARTEIRA DE TRABALHO)[:\s]*'
                r'(\d{7}[/\-]\d{5}[\-]?[A-Z]{2})',
                re.IGNORECASE
            ),
            
            # Certid√£o (Nascimento, Casamento, √ìbito): formato novo 32 d√≠gitos
            'CERTIDAO': re.compile(
                r'\b(\d{6}[\.\s]?\d{2}[\.\s]?\d{2}[\.\s]?\d{4}[\.\s]?\d[\.\s]?'
                r'\d{5}[\.\s]?\d{3}[\.\s]?\d{7}[\-\.\s]?\d{2})\b',
                re.IGNORECASE
            ),
            
            # Registro profissional: CRM, OAB, CREA, etc.
            'REGISTRO_PROFISSIONAL': re.compile(
                r'(?i)\b(CRM|OAB|CREA|CRO|CRP|CRF|COREN|CRC)[/\-\s]*'
                r'([A-Z]{2})?[\s\-]*(\d{3,6})',
                re.IGNORECASE
            ),
            
            # === CONTATO ===
            
            # Email pessoal (exclui gov.br e institucionais)
            'EMAIL_PESSOAL': re.compile(
                r'\b([a-zA-Z0-9._%+-]+@'
                r'(?!.*\.gov\.br)(?!.*\.org\.br)(?!.*\.edu\.br)'
                r'[a-zA-Z0-9.-]+\.[a-zA-Z]{2,})\b',
                re.IGNORECASE
            ),
            
            # Telefone com DDI: +55 XX XXXXX-XXXX
            'TELEFONE_DDI': re.compile(
                r'(\+55[\s\-]?\(?\d{2}\)?[\s\-]?9?\d{4}[\s\-]?\d{4})',
                re.IGNORECASE
            ),
            
            # Celular: (XX) 9XXXX-XXXX
            'CELULAR': re.compile(
                r'(?<![+\d])[\(\[]?(\d{2})[\)\]]?[\s\-]?(9\d{4})[\s\-]?(\d{4})(?!\d)',
                re.IGNORECASE
            ),
            
            # Telefone fixo: (XX) XXXX-XXXX
            'TELEFONE_FIXO': re.compile(
                r'(?<![+\d])[\(\[]?(\d{2})[\)\]]?[\s\-]?([2-5]\d{3})[\s\-]?(\d{4})(?!\d)',
                re.IGNORECASE
            ),
            
            # === ENDERE√áOS ===
            
            # Endere√ßo residencial com indicadores
            'ENDERECO_RESIDENCIAL': re.compile(
                r'(?i)(?:moro|resido|minha casa|meu endere[c√ß]o|endere[c√ß]o\s*:?)'
                r'[^\n]{0,80}?'
                r'(?:(?:rua|av|avenida|alameda|travessa|estrada|rodovia)[\s\.]+'
                r'[a-z√°√©√≠√≥√∫√†√®√¨√≤√π√¢√™√Æ√¥√ª√£√µ\s]+[\s,]+(?:n[¬∫o¬∞]?[\s\.]*)?[\d]+|'
                r'(?:casa|apto?|apartamento|lote|bloco|quadra)[\s\.]*'
                r'(?:n[¬∫o¬∞]?[\s\.]*)?[\d]+[a-z]?)',
                re.IGNORECASE | re.UNICODE
            ),
            
            # CEP: 00000-000 ou 00.000-000
            'CEP': re.compile(
                r'\b(\d{2}\.?\d{3}[\-]?\d{3})\b',
                re.IGNORECASE
            ),
            
            # Placa de ve√≠culo (Mercosul e antiga)
            'PLACA_VEICULO': re.compile(
                r'\b([A-Z]{3}[\-\s]?\d[A-Z0-9]\d{2}|'  # Mercosul: AAA0A00
                r'[A-Z]{3}[\-\s]?\d{4})\b',            # Antiga: AAA-0000
                re.IGNORECASE
            ),
            
            # === FINANCEIRO ===
            
            # Conta banc√°ria: ag√™ncia e conta
            'CONTA_BANCARIA': re.compile(
                r'(?i)(?:ag[e√™]ncia|ag\.?|conta|c/?c|c\.c\.?)[:\s]*'
                r'(\d{4,5})[\s\-]*(?:\d)?[\s\-/]*(\d{5,12})[\-]?\d?',
                re.IGNORECASE
            ),
            
            # Chave PIX (UUID, CPF, email, telefone j√° cobertos)
            'PIX_UUID': re.compile(
                r'\b([0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12})\b',
                re.IGNORECASE
            ),
            
            # Cart√£o de cr√©dito/d√©bito (16 d√≠gitos)
            'CARTAO_CREDITO': re.compile(
                r'\b(\d{4}[\s\-]?\d{4}[\s\-]?\d{4}[\s\-]?\d{4})\b',
                re.IGNORECASE
            ),
            
            # === OUTROS ===
            
            # Data de nascimento com contexto
            'DATA_NASCIMENTO': re.compile(
                r'(?i)(?:nasc|nascimento|nascido|data de nascimento|d\.?n\.?)[:\s]*'
                r'(\d{1,2}[/\-\.]\d{1,2}[/\-\.]\d{2,4})',
                re.IGNORECASE
            ),
            
            # IP Address (IPv4)
            'IP_ADDRESS': re.compile(
                r'\b(\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3})\b',
                re.IGNORECASE
            ),
            
            # Processo judicial CNJ: 0000000-00.0000.0.00.0000
            'PROCESSO_CNJ': re.compile(
                r'\b(\d{7}[\-\.]\d{2}[\-\.]\d{4}[\-\.]\d[\-\.]\d{2}[\-\.]\d{4})\b',
                re.IGNORECASE
            ),
        }
    
    @lru_cache(maxsize=1024)
    def _normalizar(self, texto: str) -> str:
        """Normaliza texto para compara√ß√£o (com cache)."""
        return unidecode(texto).upper().strip() if texto else ""
    
    def _eh_lixo(self, texto_entidade: str) -> bool:
        """Verifica se entidade √© lixo (falso positivo)."""
        if not texto_entidade or len(texto_entidade) < 3:
            return True
        
        t_norm = self._normalizar(texto_entidade)
        
        # Blocklist direta
        if t_norm in self.blocklist_total:
            return True
        
        # Termos seguros
        if any(ts in t_norm for ts in self.termos_seguros):
            return True
        
        # S√≥ n√∫meros/s√≠mbolos
        if re.match(r'^[\d/\.\-\s]+$', texto_entidade):
            return True
        
        # Palavras gen√©ricas
        palavras_bloqueadas = {
            "LIGACOES", "TELEFONICAS", "RECLAMACAO", "DENUNCIA",
            "PROTOCOLO", "PROCESSO", "MANIFESTACAO", "SOLICITACAO"
        }
        if any(p in t_norm for p in palavras_bloqueadas):
            return True
        
        return False
    
    def _contexto_negativo_cpf(self, texto: str, cpf_valor: str) -> bool:
        """Verifica se CPF est√° em contexto que invalida (exemplo, fict√≠cio, etc)."""
        idx = texto.find(cpf_valor)
        if idx == -1:
            return False
        
        # Janela de contexto
        inicio = max(0, idx - 50)
        fim = min(len(texto), idx + len(cpf_valor) + 50)
        contexto = texto[inicio:fim].upper()
        
        palavras_negativas = {
            "INVALIDO", "INV√ÅLIDO", "FALSO", "FICTICIO", "FICT√çCIO",
            "EXEMPLO", "TESTE", "FAKE", "GENERICO", "GEN√âRICO",
            "000.000.000-00", "111.111.111-11", "XXX.XXX.XXX-XX"
        }
        
        return any(p in contexto for p in palavras_negativas)
    
    def _calcular_fator_contexto(self, texto: str, inicio: int, fim: int, tipo: str) -> float:
        """Calcula fator multiplicador de confian√ßa baseado no contexto.
        
        Analisa o texto ao redor do achado para ajustar a confian√ßa:
        - Boosts: Possessivos, labels, gatilhos de contato
        - Penalidades: Contexto de teste, nega√ß√£o, institucional
        
        Args:
            texto: Texto completo sendo analisado
            inicio: Posi√ß√£o inicial do achado
            fim: Posi√ß√£o final do achado
            tipo: Tipo de PII detectado
            
        Returns:
            float: Multiplicador entre 0.6 (penalidade m√°xima) e 1.2 (boost m√°ximo)
        """
        janela = 60  # caracteres de contexto
        pre = self._normalizar(texto[max(0, inicio-janela):inicio])
        pos = self._normalizar(texto[fim:min(len(texto), fim+janela)])
        contexto_completo = pre + " " + pos
        
        fator = 1.0  # Neutro
        
        # === BOOSTS (aumentam confian√ßa) ===
        
        # Possessivo imediato antes ("meu CPF", "minha identidade")
        if re.search(r'\b(MEU|MINHA|MEUS|MINHAS)\s*:?\s*$', pre):
            fator += 0.15
        
        # Label do tipo antes (ex: "CPF:", "Email:", "Tel:")
        labels_por_tipo = {
            "CPF": [r'CPF\s*:?\s*$', r'C\.?P\.?F\.?\s*:?\s*$'],
            "EMAIL_PESSOAL": [r'E-?MAIL\s*:?\s*$', r'CORREIO\s*:?\s*$'],
            "TELEFONE": [r'TEL\.?\s*:?\s*$', r'TELEFONE\s*:?\s*$', r'CELULAR\s*:?\s*$', r'FONE\s*:?\s*$'],
            "RG": [r'RG\s*:?\s*$', r'IDENTIDADE\s*:?\s*$'],
            "CNH": [r'CNH\s*:?\s*$', r'HABILITACAO\s*:?\s*$'],
            "PIS": [r'PIS\s*:?\s*$', r'NIT\s*:?\s*$'],
            "PASSAPORTE": [r'PASSAPORTE\s*:?\s*$'],
            "CONTA_BANCARIA": [r'CONTA\s*:?\s*$', r'AGENCIA\s*:?\s*$'],
        }
        if tipo in labels_por_tipo:
            for pattern in labels_por_tipo[tipo]:
                if re.search(pattern, pre):
                    fator += 0.10
                    break
        
        # Verbo declarativo antes ("√©", "s√£o", "foi")
        if re.search(r'\b(E|√â|SAO|S√ÉO|FOI|FORAM|SERA|SER√Å)\s*:?\s*$', pre[-20:]):
            fator += 0.05
        
        # Gatilho de contato pessoal antes (para NOME)
        if tipo == "NOME":
            for gatilho in self.gatilhos_contato:
                if gatilho in pre:
                    fator += 0.10
                    break
        
        # === PENALIDADES (reduzem confian√ßa) ===
        
        # Contexto de teste/exemplo
        if re.search(r'\b(EXEMPLO|TESTE|FICTICIO|FICT√çCIO|FAKE|GENERICO|GEN√âRICO|MODELO)\b', contexto_completo):
            fator -= 0.25
        
        # Declarado inv√°lido/falso
        if re.search(r'\b(INVALIDO|INV√ÅLIDO|FALSO|ERRADO|INCORRETO)\b', contexto_completo):
            fator -= 0.30
        
        # Nega√ß√£o antes ("n√£o √© meu CPF")
        if re.search(r'\b(NAO|N√ÉO|NEM)\s+(E|√â|ERA|FOI|SAO|S√ÉO)\s*$', pre):
            fator -= 0.20
        
        # Contexto institucional (menos prov√°vel ser pessoal)
        if re.search(r'\b(DA EMPRESA|DO ORGAO|DO √ìRG√ÉO|INSTITUCIONAL|CORPORATIVO|DA SECRETARIA)\b', contexto_completo):
            fator -= 0.10
        
        # Muitos n√∫meros pr√≥ximos (pode ser tabela/lista, n√£o PII isolado)
        numeros_proximos = len(re.findall(r'\d{4,}', contexto_completo))
        if numeros_proximos >= 4:
            fator -= 0.15
        
        # Clamp entre 0.6 e 1.2
        return max(0.6, min(1.2, fator))
    
    def _calcular_confianca(self, tipo: str, texto: str, inicio: int, fim: int, 
                            score_modelo: float = None) -> float:
        """Calcula confian√ßa final: base * fator_contexto.
        
        Args:
            tipo: Tipo de PII
            texto: Texto completo
            inicio: Posi√ß√£o inicial
            fim: Posi√ß√£o final
            score_modelo: Score do modelo NER (se aplic√°vel)
            
        Returns:
            float: Confian√ßa final entre 0.0 e 1.0
        """
        # Base de confian√ßa
        if score_modelo is not None:
            base = score_modelo  # BERT retorna seu pr√≥prio score
        else:
            base = self.confianca_base.get(tipo, 0.85)
        
        # Fator de contexto
        fator = self._calcular_fator_contexto(texto, inicio, fim, tipo)
        
        # Confian√ßa final (capped em 1.0)
        return min(1.0, base * fator)
    
    def _detectar_regex(self, texto: str) -> List[PIIFinding]:
        """Detec√ß√£o por regex com valida√ß√£o de d√≠gito verificador e confian√ßa composta."""
        findings = []
        
        for tipo, pattern in self.patterns_compilados.items():
            for match in pattern.finditer(texto):
                valor = match.group(1) if match.lastindex else match.group()
                inicio, fim = match.start(), match.end()
                
                # Valida√ß√£o espec√≠fica por tipo
                if tipo == 'CPF':
                    if self._contexto_negativo_cpf(texto, valor):
                        continue
                    if not self.validador.validar_cpf(valor):
                        continue
                    confianca = self._calcular_confianca("CPF", texto, inicio, fim)
                    findings.append(PIIFinding(
                        tipo="CPF", valor=valor, confianca=confianca,
                        peso=5, inicio=inicio, fim=fim
                    ))
                
                elif tipo == 'CNPJ':
                    if not self.validador.validar_cnpj(valor):
                        continue
                    # S√≥ marca se tiver contexto de pessoa f√≠sica (MEI)
                    contexto = texto[max(0, inicio-50):fim+50].upper()
                    if any(p in contexto for p in ["MEU CNPJ", "MINHA EMPRESA", "SOU MEI", "MEI"]):
                        confianca = self._calcular_confianca("CNPJ_PESSOAL", texto, inicio, fim)
                        findings.append(PIIFinding(
                            tipo="CNPJ_PESSOAL", valor=valor, confianca=confianca,
                            peso=4, inicio=inicio, fim=fim
                        ))
                
                elif tipo == 'PIS':
                    if not self.validador.validar_pis(valor):
                        continue
                    confianca = self._calcular_confianca("PIS", texto, inicio, fim)
                    findings.append(PIIFinding(
                        tipo="PIS", valor=valor, confianca=confianca,
                        peso=5, inicio=inicio, fim=fim
                    ))
                
                elif tipo == 'CNS':
                    if not self.validador.validar_cns(valor):
                        continue
                    confianca = self._calcular_confianca("CNS", texto, inicio, fim)
                    findings.append(PIIFinding(
                        tipo="CNS", valor=valor, confianca=confianca,
                        peso=5, inicio=inicio, fim=fim
                    ))
                
                elif tipo == 'EMAIL_PESSOAL':
                    email_lower = valor.lower()
                    if any(d in email_lower for d in ['.gov.br', '.org.br', '.edu.br', 'empresa-df']):
                        continue
                    confianca = self._calcular_confianca("EMAIL_PESSOAL", texto, inicio, fim)
                    findings.append(PIIFinding(
                        tipo="EMAIL_PESSOAL", valor=valor, confianca=confianca,
                        peso=4, inicio=inicio, fim=fim
                    ))
                
                elif tipo in ['CELULAR', 'TELEFONE_FIXO', 'TELEFONE_DDI']:
                    if tipo == 'TELEFONE_DDI':
                        ctx = texto[max(0, inicio-50):inicio].lower()
                        if 'institucional' in ctx:
                            continue
                    confianca = self._calcular_confianca("TELEFONE", texto, inicio, fim)
                    findings.append(PIIFinding(
                        tipo="TELEFONE", valor=valor, confianca=confianca,
                        peso=4, inicio=inicio, fim=fim
                    ))
                
                elif tipo == 'RG':
                    confianca = self._calcular_confianca("RG", texto, inicio, fim)
                    findings.append(PIIFinding(
                        tipo="RG", valor=valor, confianca=confianca,
                        peso=5, inicio=inicio, fim=fim
                    ))
                
                elif tipo == 'CNH':
                    confianca = self._calcular_confianca("CNH", texto, inicio, fim)
                    findings.append(PIIFinding(
                        tipo="CNH", valor=valor, confianca=confianca,
                        peso=5, inicio=inicio, fim=fim
                    ))
                
                elif tipo == 'PASSAPORTE':
                    confianca = self._calcular_confianca("PASSAPORTE", texto, inicio, fim)
                    findings.append(PIIFinding(
                        tipo="PASSAPORTE", valor=valor, confianca=confianca,
                        peso=5, inicio=inicio, fim=fim
                    ))
                
                elif tipo == 'ENDERECO_RESIDENCIAL':
                    confianca = self._calcular_confianca("ENDERECO_RESIDENCIAL", texto, inicio, fim)
                    findings.append(PIIFinding(
                        tipo="ENDERECO_RESIDENCIAL", valor=valor, confianca=confianca,
                        peso=4, inicio=inicio, fim=fim
                    ))
                
                elif tipo == 'PLACA_VEICULO':
                    confianca = self._calcular_confianca("PLACA_VEICULO", texto, inicio, fim)
                    findings.append(PIIFinding(
                        tipo="PLACA_VEICULO", valor=valor, confianca=confianca,
                        peso=3, inicio=inicio, fim=fim
                    ))
                
                elif tipo == 'CONTA_BANCARIA':
                    confianca = self._calcular_confianca("CONTA_BANCARIA", texto, inicio, fim)
                    findings.append(PIIFinding(
                        tipo="CONTA_BANCARIA", valor=valor, confianca=confianca,
                        peso=4, inicio=inicio, fim=fim
                    ))
                
                elif tipo == 'PIX_UUID':
                    confianca = self._calcular_confianca("PIX", texto, inicio, fim)
                    findings.append(PIIFinding(
                        tipo="PIX", valor=valor, confianca=confianca,
                        peso=4, inicio=inicio, fim=fim
                    ))
                
                elif tipo == 'CARTAO_CREDITO':
                    confianca = self._calcular_confianca("CARTAO_CREDITO", texto, inicio, fim)
                    findings.append(PIIFinding(
                        tipo="CARTAO_CREDITO", valor=valor, confianca=confianca,
                        peso=4, inicio=inicio, fim=fim
                    ))
                
                elif tipo == 'DATA_NASCIMENTO':
                    confianca = self._calcular_confianca("DATA_NASCIMENTO", texto, inicio, fim)
                    findings.append(PIIFinding(
                        tipo="DATA_NASCIMENTO", valor=valor, confianca=confianca,
                        peso=3, inicio=inicio, fim=fim
                    ))
                
                elif tipo == 'TITULO_ELEITOR':
                    if not self.validador.validar_titulo_eleitor(valor):
                        continue
                    confianca = self._calcular_confianca("TITULO_ELEITOR", texto, inicio, fim)
                    findings.append(PIIFinding(
                        tipo="TITULO_ELEITOR", valor=valor, confianca=confianca,
                        peso=5, inicio=inicio, fim=fim
                    ))
                
                elif tipo == 'CTPS':
                    confianca = self._calcular_confianca("CTPS", texto, inicio, fim)
                    findings.append(PIIFinding(
                        tipo="CTPS", valor=valor, confianca=confianca,
                        peso=5, inicio=inicio, fim=fim
                    ))
                
                elif tipo == 'CERTIDAO':
                    confianca = self._calcular_confianca("CERTIDAO", texto, inicio, fim)
                    findings.append(PIIFinding(
                        tipo="CERTIDAO", valor=valor, confianca=confianca,
                        peso=5, inicio=inicio, fim=fim
                    ))
                
                elif tipo == 'REGISTRO_PROFISSIONAL':
                    confianca = self._calcular_confianca("REGISTRO_PROFISSIONAL", texto, inicio, fim)
                    findings.append(PIIFinding(
                        tipo="REGISTRO_PROFISSIONAL", valor=valor, confianca=confianca,
                        peso=5, inicio=inicio, fim=fim
                    ))
                
                elif tipo == 'CEP':
                    # CEP s√≥ √© PII se estiver em contexto de endere√ßo pessoal
                    contexto = texto[max(0, inicio-50):fim+50].upper()
                    if any(p in contexto for p in ["MORO", "RESIDO", "MINHA CASA", "MEU ENDERECO"]):
                        confianca = self._calcular_confianca("CEP", texto, inicio, fim)
                        findings.append(PIIFinding(
                            tipo="CEP", valor=valor, confianca=confianca,
                            peso=3, inicio=inicio, fim=fim
                        ))
                
                elif tipo == 'PROCESSO_CNJ':
                    confianca = self._calcular_confianca("PROCESSO_CNJ", texto, inicio, fim)
                    findings.append(PIIFinding(
                        tipo="PROCESSO_CNJ", valor=valor, confianca=confianca,
                        peso=3, inicio=inicio, fim=fim
                    ))
        
        return findings
    
    def _extrair_nomes_gatilho(self, texto: str) -> List[PIIFinding]:
        """Extrai nomes ap√≥s gatilhos de contato (sempre PII) com confian√ßa composta."""
        findings = []
        texto_upper = self._normalizar(texto)
        
        for gatilho in self.gatilhos_contato:
            if gatilho not in texto_upper:
                continue
            
            idx = texto_upper.find(gatilho) + len(gatilho)
            resto = texto[idx:idx+60].strip()
            
            # Procura nome ap√≥s o gatilho
            match = re.search(
                r'\b(?:o|a|do|da)?\s*([A-Z][a-z√°√©√≠√≥√∫√†√®√¨√≤√π√¢√™√Æ√¥√ª√£√µ]+(?:\s+[A-Z][a-z√°√©√≠√≥√∫√†√®√¨√≤√π√¢√™√Æ√¥√ª√£√µ]+)*)',
                resto
            )
            
            if match:
                nome = match.group(1).strip()
                nome_upper = self._normalizar(nome)
                
                # Ignora cargos e termos gen√©ricos
                if nome_upper in self.cargos_autoridade:
                    continue
                if nome_upper in self.indicadores_servidor:
                    continue
                if len(nome) <= 3:
                    continue
                
                inicio = idx + match.start()
                fim = idx + match.end()
                # Usa base NOME_GATILHO (0.85) com fator de contexto
                confianca = self._calcular_confianca("NOME", texto, inicio, fim)
                # Boost adicional porque tem gatilho (j√° √© forte indicador)
                confianca = min(1.0, confianca * 1.05)
                
                findings.append(PIIFinding(
                    tipo="NOME", valor=nome, confianca=confianca,
                    peso=4, inicio=inicio, fim=fim
                ))
        
        # Nomes ap√≥s "contra" (reclama√ß√£o contra Pedro)
        if "CONTRA" in texto_upper:
            idx = texto_upper.find("CONTRA") + 6
            resto = texto[idx:idx+50].strip().strip(".,;:'\"-")
            
            match = re.search(r"^([A-Z][a-z√°√©√≠√≥√∫√†√®√¨√≤√π√¢√™√Æ√¥√ª√£√µ]+)", resto)
            if match:
                nome = match.group(1).strip()
                nome_upper = self._normalizar(nome)
                
                if len(nome) > 3 and nome_upper not in self.blocklist_total:
                    inicio = idx
                    fim = idx + len(nome)
                    # Base menor para "contra" (0.80)
                    base = self.confianca_base.get("NOME_CONTRA", 0.80)
                    fator = self._calcular_fator_contexto(texto, inicio, fim, "NOME")
                    confianca = min(1.0, base * fator)
                    
                    findings.append(PIIFinding(
                        tipo="NOME", valor=nome, confianca=confianca,
                        peso=4, inicio=inicio, fim=fim
                    ))
        
        return findings
    
    def _deve_ignorar_nome(self, texto: str, inicio: int) -> bool:
        """Determina se nome deve ser ignorado (imunidade funcional)."""
        # Contexto antes do nome
        pre_text = self._normalizar(texto[max(0, inicio-100):inicio])
        # Contexto ap√≥s o nome (pr√≥ximos 100 chars)
        pos_text = self._normalizar(texto[inicio:min(len(texto), inicio+100)])
        
        # Gatilho de contato ANULA imunidade
        for gatilho in self.gatilhos_contato:
            if gatilho in pre_text:
                return False
        
        # "Funcion√°rio do m√™s" = imune (contexto de elogio)
        if "FUNCIONARIO DO MES" in pre_text or "FUNCIONARIA DO MES" in pre_text:
            return True
        
        # Cargo + institui√ß√£o = imune
        for cargo in self.cargos_autoridade:
            if re.search(rf"\b{cargo}\.?\s*$", pre_text):
                instituicoes = {
                    "SECRETARIA", "ADMINISTRACAO", "DEPARTAMENTO", 
                    "DIRETORIA", "GDF", "SEEDF", "RESPONSAVEL"
                }
                if any(inst in pos_text for inst in instituicoes):
                    return True
        
        # Servidor em contexto funcional = imune
        if any(ind in pre_text for ind in self.indicadores_servidor):
            return True
        
        return False
    
    def _detectar_ner(self, texto: str) -> List[PIIFinding]:
        """Detec√ß√£o de nomes usando modelos NER (BERT e spaCy) com confian√ßa composta."""
        findings = []
        threshold = 0.75
        
        # BERT NER (prim√°rio)
        if self.nlp_bert:
            try:
                entidades = self.nlp_bert(texto)
                for ent in entidades:
                    # Aceita PER (pessoa) do modelo
                    if ent['entity_group'] in ['PER', 'PESSOA', 'B-PER', 'I-PER']:
                        if ent['score'] < threshold:
                            continue
                        
                        palavra = ent['word'].strip()
                        
                        # Filtros de qualidade
                        if len(palavra) <= 3:
                            continue
                        if " " not in palavra:  # Precisa ter nome + sobrenome
                            continue
                        if self._eh_lixo(palavra):
                            continue
                        if self._deve_ignorar_nome(texto, ent['start']):
                            continue
                        
                        inicio, fim = ent['start'], ent['end']
                        # BERT: usa score do modelo como base, aplica fator de contexto
                        score_bert = float(ent['score'])
                        fator = self._calcular_fator_contexto(texto, inicio, fim, "NOME")
                        confianca = min(1.0, score_bert * fator)
                        
                        findings.append(PIIFinding(
                            tipo="NOME", valor=palavra,
                            confianca=confianca, peso=4,
                            inicio=inicio, fim=fim
                        ))
            except Exception as e:
                logger.warning(f"Erro no BERT NER: {e}")
        
        # spaCy NER (complementar)
        if self.nlp_spacy:
            try:
                doc = self.nlp_spacy(texto)
                for ent in doc.ents:
                    if ent.label_ != 'PER':
                        continue
                    
                    # Filtros
                    if len(ent.text) <= 3:
                        continue
                    if " " not in ent.text:
                        continue
                    if self._eh_lixo(ent.text):
                        continue
                    if self._deve_ignorar_nome(texto, ent.start_char):
                        continue
                    
                    # Evita duplicatas com BERT
                    if not any(f.valor.lower() == ent.text.lower() for f in findings):
                        inicio, fim = ent.start_char, ent.end_char
                        # spaCy: usa base fixa (0.70), aplica fator de contexto
                        base = self.confianca_base.get("NOME_SPACY", 0.70)
                        fator = self._calcular_fator_contexto(texto, inicio, fim, "NOME")
                        confianca = min(1.0, base * fator)
                        
                        findings.append(PIIFinding(
                            tipo="NOME", valor=ent.text,
                            confianca=confianca, peso=4,
                            inicio=inicio, fim=fim
                        ))
            except Exception as e:
                logger.warning(f"Erro no spaCy: {e}")
        
        return findings
    
    def detect(self, text: str) -> Tuple[bool, List[Dict], str, float]:
        """Detecta PII no texto usando ensemble de alta recall + confian√ßa probabil√≠stica.
        
        Estrat√©gia: OR - qualquer detector positivo = PII
        Isso maximiza recall para conformidade LAI/LGPD.
        
        Confian√ßa: Usa sistema probabil√≠stico com calibra√ß√£o isot√¥nica e 
        combina√ß√£o via Log-Odds quando dispon√≠vel.
        
        Args:
            text: Texto a ser analisado
            
        Returns:
            Tuple contendo:
            - is_pii (bool): True se cont√©m PII
            - findings (List[Dict]): Lista de PIIs encontrados
            - nivel_risco (str): CRITICO, ALTO, MODERADO, BAIXO ou SEGURO
            - confianca (float): Score de confian√ßa 0-1
        """
        if not text or not text.strip():
            return False, [], "SEGURO", 1.0
        
        # === USA SISTEMA PROBABIL√çSTICO SE DISPON√çVEL ===
        if self.use_probabilistic_confidence and self.confidence_calculator:
            return self._detect_with_probabilistic_confidence(text)
        
        # === FALLBACK: SISTEMA LEGADO ===
        return self._detect_legacy(text)
    
    def _detect_with_probabilistic_confidence(self, text: str) -> Tuple[bool, List[Dict], str, float]:
        """Detec√ß√£o com sistema de confian√ßa probabil√≠stica.
        
        Usa calibra√ß√£o isot√¥nica + combina√ß√£o log-odds para calcular
        confian√ßa de cada entidade e m√©tricas de documento.
        """
        # Coleta fontes usadas
        sources_used = []
        if self.nlp_bert:
            sources_used.append("bert_ner")
        if self.nlp_spacy:
            sources_used.append("spacy")
        sources_used.append("regex")
        
        # === ENSEMBLE DE DETEC√á√ÉO COM RASTREAMENTO DE FONTE ===
        all_raw_detections: List[Dict] = []
        
        # 1. Regex com valida√ß√£o de DV
        regex_findings = self._detectar_regex(text)
        for f in regex_findings:
            all_raw_detections.append({
                "tipo": f.tipo,
                "valor": f.valor,
                "start": f.inicio,
                "end": f.fim,
                "source": "regex",
                "score": f.confianca,
                "peso": f.peso
            })
        
        # 2. Nomes ap√≥s gatilhos
        gatilho_findings = self._extrair_nomes_gatilho(text)
        for f in gatilho_findings:
            all_raw_detections.append({
                "tipo": f.tipo,
                "valor": f.valor,
                "start": f.inicio,
                "end": f.fim,
                "source": "gatilho",
                "score": f.confianca,
                "peso": f.peso
            })
        
        # 3. NER (BERT + spaCy) - rastreia separadamente
        if self.nlp_bert:
            bert_findings = self._detectar_ner_bert_only(text)
            for f in bert_findings:
                all_raw_detections.append({
                    "tipo": f.tipo,
                    "valor": f.valor,
                    "start": f.inicio,
                    "end": f.fim,
                    "source": "bert_ner",
                    "score": f.confianca,
                    "peso": f.peso
                })
        
        if self.nlp_spacy:
            spacy_findings = self._detectar_ner_spacy_only(text)
            for f in spacy_findings:
                all_raw_detections.append({
                    "tipo": f.tipo,
                    "valor": f.valor,
                    "start": f.inicio,
                    "end": f.fim,
                    "source": "spacy",
                    "score": f.confianca,
                    "peso": f.peso
                })
        
        # Usa calculador probabil√≠stico
        doc_confidence = self.confidence_calculator.process_raw_detections(
            raw_detections=all_raw_detections,
            sources_used=sources_used,
            text=text
        )
        
        # Converte para formato de retorno legado
        if not doc_confidence.has_pii:
            return False, [], "SEGURO", doc_confidence.confidence_no_pii
        
        # Extrai findings no formato esperado
        findings_dict = []
        for entity in doc_confidence.entities:
            findings_dict.append({
                "tipo": entity.tipo,
                "valor": entity.valor,
                "confianca": entity.confianca
            })
        
        # Confian√ßa do documento = confidence_all_found (ou min_entity como fallback)
        doc_conf = doc_confidence.confidence_all_found or doc_confidence.confidence_min_entity or 0.9
        
        return True, findings_dict, doc_confidence.risco, doc_conf
    
    def _detect_legacy(self, text: str) -> Tuple[bool, List[Dict], str, float]:
        """Sistema de detec√ß√£o legado (fallback quando m√≥dulo probabil√≠stico indispon√≠vel)."""
        # === ENSEMBLE DE DETEC√á√ÉO ===
        all_findings: List[PIIFinding] = []
        
        # 1. Regex com valida√ß√£o de DV (mais preciso)
        regex_findings = self._detectar_regex(text)
        all_findings.extend(regex_findings)
        
        # 2. Nomes ap√≥s gatilhos de contato (sempre PII)
        gatilho_findings = self._extrair_nomes_gatilho(text)
        all_findings.extend(gatilho_findings)
        
        # 3. NER (BERT + spaCy)
        ner_findings = self._detectar_ner(text)
        all_findings.extend(ner_findings)
        
        # === DEDUPLICA√á√ÉO COM PRIORIDADE ===
        final_dict: Dict[str, PIIFinding] = {}
        for finding in all_findings:
            key = finding.valor.lower().strip()
            
            if key not in final_dict:
                final_dict[key] = finding
            elif finding.peso > final_dict[key].peso:
                final_dict[key] = finding
            elif finding.peso == final_dict[key].peso and finding.confianca > final_dict[key].confianca:
                final_dict[key] = finding
        
        # === RESULTADO FINAL ===
        final_list = list(final_dict.values())
        
        # Filtra apenas PII relevantes (peso >= 3)
        pii_relevantes = [f for f in final_list if f.peso >= 3]
        
        if not pii_relevantes:
            return False, [], "SEGURO", 1.0
        
        # Calcula risco m√°ximo
        max_peso = max(f.peso for f in pii_relevantes)
        
        # Mapeamento de risco
        risco_map = {
            5: "CRITICO",
            4: "ALTO",
            3: "MODERADO",
            2: "BAIXO",
            0: "SEGURO"
        }
        nivel_risco = risco_map.get(max_peso, "MODERADO")
        
        # Confian√ßa baseada no melhor achado
        max_confianca = max(f.confianca for f in pii_relevantes)
        
        # Converte para dict para compatibilidade
        findings_dict = [
            {
                "tipo": f.tipo,
                "valor": f.valor,
                "confianca": f.confianca  # Corrigido: era 'conf', frontend espera 'confianca'
            }
            for f in pii_relevantes
        ]
        
        return True, findings_dict, nivel_risco, max_confianca
    
    def detect_extended(self, text: str) -> Dict:
        """Detecta PII com m√©tricas de confian√ßa probabil√≠stica extendidas.
        
        Retorna informa√ß√µes adicionais sobre confian√ßa:
        - confidence_no_pii: P(n√£o existe PII) quando nada detectado
        - confidence_all_found: P(encontramos todo PII) quando tem detec√ß√µes
        - confidence_min_entity: Menor confian√ßa entre entidades
        
        Args:
            text: Texto a ser analisado
            
        Returns:
            Dict com estrutura:
            {
                "has_pii": bool,
                "classificacao": "P√öBLICO" ou "N√ÉO P√öBLICO",
                "risco": "CR√çTICO"/"ALTO"/"MODERADO"/"BAIXO"/"SEGURO",
                "confidence": {
                    "no_pii": float (0-1),
                    "all_found": float ou None,
                    "min_entity": float ou None
                },
                "sources_used": ["bert_ner", "spacy", "regex", ...],
                "entities": [{"tipo", "valor", "confianca", ...}, ...],
                "total_entities": int
            }
        """
        if not text or not text.strip():
            return {
                "has_pii": False,
                "classificacao": "P√öBLICO",
                "risco": "SEGURO",
                "confidence": {
                    "no_pii": 0.9999999999,
                    "all_found": None,
                    "min_entity": None
                },
                "sources_used": [],
                "entities": [],
                "total_entities": 0
            }
        
        # Coleta fontes usadas
        sources_used = []
        if self.nlp_bert:
            sources_used.append("bert_ner")
        if self.nlp_spacy:
            sources_used.append("spacy")
        sources_used.append("regex")  # Sempre dispon√≠vel
        
        # Se m√≥dulo de confian√ßa n√£o dispon√≠vel, usa detect() e converte
        if not self.use_probabilistic_confidence:
            is_pii, findings, nivel_risco, conf = self.detect(text)
            return {
                "has_pii": is_pii,
                "classificacao": "N√ÉO P√öBLICO" if is_pii else "P√öBLICO",
                "risco": nivel_risco,
                "confidence": {
                    "no_pii": 1.0 - conf if not is_pii else 0.0,
                    "all_found": conf if is_pii else None,
                    "min_entity": conf if is_pii else None
                },
                "sources_used": sources_used,
                "entities": findings,
                "total_entities": len(findings)
            }
        
        # === ENSEMBLE DE DETEC√á√ÉO COM RASTREAMENTO DE FONTE ===
        all_raw_detections: List[Dict] = []
        
        # 1. Regex com valida√ß√£o de DV
        regex_findings = self._detectar_regex(text)
        for f in regex_findings:
            all_raw_detections.append({
                "tipo": f.tipo,
                "valor": f.valor,
                "start": f.inicio,
                "end": f.fim,
                "source": "regex",
                "score": f.confianca,
                "peso": f.peso
            })
        
        # 2. Nomes ap√≥s gatilhos
        gatilho_findings = self._extrair_nomes_gatilho(text)
        for f in gatilho_findings:
            all_raw_detections.append({
                "tipo": f.tipo,
                "valor": f.valor,
                "start": f.inicio,
                "end": f.fim,
                "source": "gatilho",
                "score": f.confianca,
                "peso": f.peso
            })
        
        # 3. NER (BERT + spaCy) - precisa rastrear separadamente
        if self.nlp_bert:
            bert_findings = self._detectar_ner_bert_only(text)
            for f in bert_findings:
                all_raw_detections.append({
                    "tipo": f.tipo,
                    "valor": f.valor,
                    "start": f.inicio,
                    "end": f.fim,
                    "source": "bert_ner",
                    "score": f.confianca,
                    "peso": f.peso
                })
        
        if self.nlp_spacy:
            spacy_findings = self._detectar_ner_spacy_only(text)
            for f in spacy_findings:
                all_raw_detections.append({
                    "tipo": f.tipo,
                    "valor": f.valor,
                    "start": f.inicio,
                    "end": f.fim,
                    "source": "spacy",
                    "score": f.confianca,
                    "peso": f.peso
                })
        
        # Usa calculador probabil√≠stico
        doc_confidence = self.confidence_calculator.process_raw_detections(
            raw_detections=all_raw_detections,
            sources_used=sources_used,
            text=text
        )
        
        return doc_confidence.to_dict()
    
    def _detectar_ner_bert_only(self, texto: str) -> List[PIIFinding]:
        """Detecta apenas com BERT NER (para rastreamento de fonte)."""
        findings = []
        
        if not self.nlp_bert:
            return findings
        
        try:
            # Trunca texto se necess√°rio (BERT tem limite de tokens)
            texto_truncado = texto[:4096] if len(texto) > 4096 else texto
            
            resultados = self.nlp_bert(texto_truncado)
            for ent in resultados:
                if ent['entity_group'] != 'PER':
                    continue
                
                nome = ent['word']
                score = ent['score']
                
                # Filtros
                if len(nome) <= 3:
                    continue
                if " " not in nome:
                    continue
                if self._eh_lixo(nome):
                    continue
                if self._deve_ignorar_nome(texto, ent['start']):
                    continue
                
                inicio, fim = ent['start'], ent['end']
                
                findings.append(PIIFinding(
                    tipo="NOME", valor=nome,
                    confianca=score, peso=4,
                    inicio=inicio, fim=fim
                ))
        except Exception as e:
            logger.warning(f"Erro no BERT NER: {e}")
        
        return findings
    
    def _detectar_ner_spacy_only(self, texto: str) -> List[PIIFinding]:
        """Detecta apenas com spaCy NER (para rastreamento de fonte)."""
        findings = []
        
        if not self.nlp_spacy:
            return findings
        
        try:
            doc = self.nlp_spacy(texto)
            for ent in doc.ents:
                if ent.label_ != 'PER':
                    continue
                
                # Filtros
                if len(ent.text) <= 3:
                    continue
                if " " not in ent.text:
                    continue
                if self._eh_lixo(ent.text):
                    continue
                if self._deve_ignorar_nome(texto, ent.start_char):
                    continue
                
                inicio, fim = ent.start_char, ent.end_char
                base = self.confianca_base.get("NOME_SPACY", 0.70)
                fator = self._calcular_fator_contexto(texto, inicio, fim, "NOME")
                confianca = min(1.0, base * fator)
                
                findings.append(PIIFinding(
                    tipo="NOME", valor=ent.text,
                    confianca=confianca, peso=4,
                    inicio=inicio, fim=fim
                ))
        except Exception as e:
            logger.warning(f"Erro no spaCy: {e}")
        
        return findings


# === FUN√á√ÉO DE CONVENI√äNCIA ===

def criar_detector(usar_gpu: bool = True, use_probabilistic_confidence: bool = True) -> PIIDetector:
    """Factory function para criar detector configurado.
    
    Args:
        usar_gpu: Se deve usar GPU para modelos (default: True)
        use_probabilistic_confidence: Se deve usar sistema de confian√ßa 
            probabil√≠stica (default: True)
    """
    return PIIDetector(usar_gpu=usar_gpu, use_probabilistic_confidence=use_probabilistic_confidence)


# === TESTE R√ÅPIDO ===

if __name__ == "__main__":
    detector = criar_detector(usar_gpu=False)
    
    testes = [
        "Meu CPF √© 529.982.247-25 e moro na Rua das Flores, 123",
        "A Dra. Maria da Secretaria de Administra√ß√£o informou que...",
        "Preciso falar com o Jo√£o Silva sobre o processo",
        "O servidor Jos√© Santos do DETRAN atendeu a demanda",
        "Meu telefone √© +55 61 99999-8888 para contato",
        "Email: joao.silva@gmail.com",
        "Protocolo SEI 00000-00000000/2024-00 do GDF",
    ]
    
    for texto in testes:
        is_pii, findings, risco, conf = detector.detect(texto)
        status = "üî¥ PII" if is_pii else "üü¢ SEGURO"
        print(f"\n{status} [{risco}] (conf: {conf:.2f})")
        print(f"Texto: {texto[:80]}...")
        if findings:
            for f in findings:
                print(f"  ‚Üí {f['tipo']}: {f['valor']}")